---
title: Which Model to Use?
date: 2023-02-16
description:  There is a lot of ML models available that we can use for our next project. The question is, which one?
alt: Which Model to Use?
published: true

sitemap:
    lastmod: 2023-02-15
    changefreq: monthly
    priority: 0.8
---

From the past 3 decades (from the 90s), AI has started to be more and more popular following the boom of hardware technology that keeps evolving to larger storage, faster speed, and with lower price. Until now, there is a lot of ML models proposed by research papers around the world to the point that it become "obsolete" just after months of released. But "obsolete" is not the best term to use for this scenario, each models have its own strength and weakness from various aspects and theres a wide spectrum that we can look at to choose the right model.

### What is Your Model Constraint?

Before we can choose our model, we first need to understand the project requirements. And from there we can extract the constraints. These are some of the important ones:

- **Accuracy**

	Does your model need to be super accurate in order to have a reliable system? Can it tolerate some false positives? can it tolerate some false negatives? does 70% of accuracy enough? or does it needs to be >80%? or perhap >90%?
	<br/>
	Obviously, the higher the better. But sometimes we don't have that privilege to get super high accuracy, especially in certain situations where the data is limited, or in some cases the label could also be vague and subject to interpretations. It is important to identify what is the end-goal threshold.

- **Inference Speed**

	Does it need to be fast? or does it need to be realtime-fast? what is the longest acceptable inferencing time or **processing** time?
	<br/>
	I bolded the keyword "processing" because that is what often mislooked when deploying the model in production. Processing consist of data preprocessing + data validation + model inferencing + model output validation + data upload + other relevant operations. Let say the maximum acceptable processing time is 2 seconds but the model inferencing time itself already took 1.5 seconds, you would not have enough time to complete all the other operations. You would need faster model let say with 0.5 second of inferencing time in order to keep everything within constraint.

- **Deployment Environment**

	Where do you need to deploy the model? on cloud or on edge devices? specifically, what edge device model will be used? 
	<br/>
	Cloud tends to have more powerful compute power while edge devices are very limited. Certain edge devices also limited to certain machine learning libraries only. This is ultimately the biggest reason to answer these questions first before training the model.

### So Which Model Should I use?

TBC

	